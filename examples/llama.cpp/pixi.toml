[workspace]
authors = ["Silvio Traversaro <silvio@traversaro.it>"]
channels = ["https://prefix.dev/rock-the-conda", "https://prefix.dev/conda-forge"]
name = "llama.cpp"
platforms = ["linux-64"]

[dependencies]

# Workaround for missing run_exports, will be fixed in next rebuild
"llama.cpp" = { version = "6904.*", build = "*rocm*" }
hipblas = "*"
rocblas = "*"
roctracer = "*"
rocsolver = "*"
rocm-core = "7.0.2.*"
curl = "*"

[feature.cpu.dependencies]
"llama.cpp" = { version = "6904.*", build = "*cpu*" }
curl = "*"

[feature.tasks.tasks]
download_model = { cmd = "curl -L -o gemma-3-1b-it-Q4_K_M.gguf https://huggingface.co/ggml-org/gemma-3-1b-it-GGUF/resolve/main/gemma-3-1b-it-Q4_K_M.gguf", outputs = [
  "gemma-3-1b-it-Q4_K_M.gguf",
] }
benchmark = {cmd="llama-bench -m ./gemma-3-1b-it-Q4_K_M.gguf", depends-on="download_model"}


[environments]
default = { features = ["tasks"] }
cpu = { features = ["cpu", "tasks"], no-default-feature = true }
